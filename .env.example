# initial superuser credentials
# These will be used to create the first superuser in the application
# Make sure to change these in production
FIRST_SUPERUSER="admin"
FIRST_SUPERUSER_PASSWORD="admin"

# Project settings
SHORT_SUMMARY_LENGTH=100  # Characters
MAX_RESULTS=5
MAX_RETRIES=3
RETRY_DELAY_BASE=2  # Base delay in seconds between retries
RETRY_JITTER=0.5  # Random jitter added to retry delay

# Database settings
POSTGRES_USER="postgres"
POSTGRES_PASSWORD="postgres"
POSTGRES_DB="arxiv_papers"
POSTGRES_SERVER="postgres_db"  # Use the service name defined in docker-compose.yml
POSTGRES_PORT=5432

# QDRANT
QDRANT_HOST="host.docker.internal"  # Magic DNS for host machine
QDRANT_PORT=6334
COLLECTION_NAME="arxiv_ml_papers"
# VECTOR_DIM=1536  # Dimension of the embedding model (moved to embedding section)

# Docker images
DOCKER_IMAGE_BACKEND=backend
DOCKER_IMAGE_FRONTEND=frontend

# Frontend environment variables for local development
VITE_API_BASE_URL=http://localhost:8000

# LLM settings (choose one provider)
# Option 1: OpenAI
# LLM_PROVIDER=openai
OPENAI_MODEL="gpt-3.5-turbo"
OPENAI_EMBED_MODEL="text-embedding-3-small"

# Embedding model (works with both OpenAI and Ollama)
OLAMA_EMBED_MODEL=bge-large
VECTOR_DIM=1024  # BGE-Large has 1024 dimensions (changed from 1536 for OpenAI)

# Option 2: Ollama (local)
LLM_PROVIDER=ollama
OLLAMA_MODEL=deepseek-r1:8b
OLLAMA_BASE_URL=http://localhost:11434
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=512
LLM_CONTEXT_WINDOW=4096
OLLAMA_PLATFORM=linux/arm64